# LangGraph Research AI Agent

A powerful research automation system built on LangChain with advanced scoping capabilities. This project extends the LangGraph Academy example to create a self-hosted AI research assistant that leverages Ollama as the LLM backend and Tavily's free tier for web search, making it completely cost-effective.

[![LangGraph](https://langchain-ai.github.io/langgraph/assets/langgraph-logo.svg)](https://langchain-ai.github.io/langgraph/)

## ğŸ¯ Project Overview

The LangGraph Research AI Agent is an intelligent research automation system designed to:

- **Automate complex research tasks** through iterative web search and synthesis
- **Generate comprehensive reports** with structured data and insights
- **Implement advanced scoping mechanisms** to ensure research relevance and quality
- **Leverage self-hosted AI infrastructure** using Ollama for cost-effective operations
- **Integrate Tavily's free tier** for web search capabilities

Built on the foundation of [LangGraph Academy](https://langchain-ai.github.io/langgraph/) examples, this agent extends the basic research capabilities with sophisticated workflow management, multi-agent coordination, and intelligent scoping.

## âš¡ Key Features

### Research Automation
- **Iterative web search** using Tavily integration
- **Automated data synthesis** from multiple sources
- **Intelligent report generation** with structured outputs
- **Multi-agent coordination** for complex research tasks

### Advanced Scoping
- **User clarification workflow** to ensure research relevance
- **Research brief generation** for focused investigations
- **Structured decision-making** using Pydantic models
- **Context-aware research planning**

### Cost-Effective Architecture
- **Ollama integration** for self-hosted LLM backend
- **Tavily free tier** for web search capabilities
- **No API costs** for basic operations
- **Local development** support

### Report Generation
- **Comprehensive research reports** with citations
- **Structured data presentation** (tables, lists, sections)
- **Cross-referenced sources** and evidence
- **Actionable insights** and recommendations

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Ollama running locally (accessible at `http://localhost:11434/v1`)
- Tavily API key (free tier available)

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/StefanWittmann/langgraph-chatbot.git
cd langgraph-chatbot
```

2. **Set up virtual environment:**
```bash
uv init langgraph-chatbot --python 3.13
uv sync
```

3. **Install dependencies:**
```bash
uv pip install "langgraph-cli[inmem]"
source .venv/bin/activate
```

### Configuration

1. **Copy environment variables:**
```bash
cp .env.example .env
```

2. **Edit `.env` file** with your specific configuration:
```env
# Ollama configuration (self-hosted LLM)
OPENAI_API_KEY=ollama
OPENAI_BASE_URL=http://localhost:11434/v1
OPENAI_MODEL=gpt-oss:20b

# Tavily API key (free tier)
TAVILY_API_KEY=your-tavily-api-key
```

### Running the Agent

1. **Start the development server:**
```bash
uv run langgraph dev
```

2. **Access the application:**
- The agent will be available at `http://localhost:2024`
- Ensure Ollama is running and accessible

## ğŸ“š Example Reports

The [`reports/`](reports/) directory contains sample outputs generated by the research agent, demonstrating its capabilities:

- **Christmas 2025 Pastry Landscape** - Comprehensive market analysis with trend data, recipe popularity, and regional insights
- **Global Investment Portfolio 2026** - Financial research with market projections and investment strategies
- **Gold vs Silver 2026** - Commodity market analysis with price forecasts and economic factors
- **Milk Industry Analysis** - Agricultural research with production trends and market dynamics

Each report features:
- **Structured sections** with clear headings
- **Data tables** and comparative analysis
- **Cited sources** and evidence-based insights
- **Actionable recommendations** for different stakeholders

## ğŸ—ï¸ Architecture & Workflow

### High-Level Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 LangGraph Research Agent              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Scoping    â”‚    â”‚  Research   â”‚    â”‚  Multi-   â”‚  â”‚
â”‚  â”‚  Agent      â”‚â”€â”€â”€â–¶â”‚  Agent      â”‚â”€â”€â”€â–¶â”‚  Agent    â”‚  â”‚
â”‚  â”‚  (Scope)    â”‚    â”‚  (Research) â”‚    â”‚  Supervis.â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

1. **Scoping Agent** (`src/research_agent_scope.py`)
   - User clarification workflow
   - Research brief generation
   - Structured decision-making

2. **Research Agent** (`src/research_agent.py`)
   - Iterative web search with Tavily
   - Data synthesis and analysis
   - Report compression and formatting

3. **Multi-Agent Supervisor** (`src/multi_agent_supervisor.py`)
   - Agent coordination and workflow management
   - State management and routing
   - Final report generation

### LangChain Integration

- **State management** using Pydantic models
- **Tool binding** for Tavily search and analysis tools
- **Conditional routing** based on research progress
- **Structured outputs** for deterministic decision-making

### Self-Hosted Infrastructure

- **Ollama LLM backend** for cost-effective operations
- **Local API endpoints** for privacy and control
- **Environment-based configuration** for flexibility

## âš™ï¸ Configuration

### Environment Variables

Configure the agent through `.env` file:

```env
# LLM Configuration
OPENAI_API_KEY=ollama          # Use "ollama" for self-hosted
OPENAI_BASE_URL=http://localhost:11434/v1
OPENAI_MODEL=gpt-oss:20b       # Model name from `ollama list`

# External Services
TAVILY_API_KEY=your-api-key    # Get from Tavily dashboard
MCP_API_URL=http://localhost:8080
MCP_API_KEY=your-mcp-key      # Optional for MCP integration

# Development
VITE_APP_URL=http://localhost:5173
```

### Runtime Parameters

Adjust agent behavior through code configuration:

- **Temperature settings** in model initialization
- **Token limits** for different model instances
- **Tool selection** in agent workflows
- **Routing logic** for research progression

## ğŸ¤ Contributing

We welcome contributions to improve the LangGraph Research Agent!

### Development Setup

1. **Install development dependencies:**
```bash
uv pip install -e ".[dev]"
```

2. **Run linting and formatting:**
```bash
ruff check .
ruff format .
```

### Contribution Guidelines

- **Fork the repository** and create feature branches
- **Follow Google Python style guide** (configured in `pyproject.toml`)
- **Write comprehensive tests** for new features
- **Update documentation** for any changes
- **Maintain backward compatibility** where possible
- **Use descriptive commit messages** following conventional commits

### Testing

- **Unit tests** for individual components
- **Integration tests** for agent workflows
- **End-to-end tests** for complete research cycles
- **Performance benchmarks** for optimization

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ”§ Troubleshooting

### Common Issues

1. **Ollama connection problems:**
   - Ensure Ollama is running: `ollama serve`
   - Verify model is available: `ollama list`
   - Check URL matches `.env` configuration

2. **Tavily API errors:**
   - Verify API key is correct
   - Check free tier limits
   - Test API connectivity

3. **Port conflicts:**
   - Kill existing processes: `lsof -ti:2024 | xargs kill -9`
   - Use different port if needed

4. **Dependency issues:**
   - Clean reinstall: `uv sync --clean`
   - Check Python version compatibility

## ğŸ“¬ Contact

For questions or support, please open an issue on the GitHub repository.

---

**Key Differences from Original LangGraph Example:**
- Extended with Ollama self-hosted LLM backend
- removed deep_research subfolder in src folder
